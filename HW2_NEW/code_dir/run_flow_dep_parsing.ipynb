{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from utils import get_vocabs_dep_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data_new'\n",
    "path_train = os.path.join(data_dir, 'train.labeled')\n",
    "path_test = os.path.join(data_dir, 'test.labeled')\n",
    "# path_train = os.path.join(data_dir, 'train_short.labeled')\n",
    "# path_test = os.path.join(data_dir, 'test_short.labeled')\n",
    "\n",
    "# get only train vocabs to know which words are unknown in test\n",
    "paths_list_train = [path_train]\n",
    "word_dict_train, pos_dict_train = get_vocabs_dep_parser(paths_list_train)\n",
    "\n",
    "paths_list_all = [path_train, path_test]\n",
    "word_dict_all, pos_dict_all = get_vocabs_dep_parser(paths_list_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_train - data_new/train.labeled\n",
      "path_test - data_new/test.labeled\n",
      "idx_pos_mappings - [0, 1, 2, 3, '#', '$', \"''\", '(', ')', ',', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n",
      "pos_idx_mappings - {'<pad>': 0, '<unk>': 1, '<root>': 2, '<root_pos>': 3, '#': 4, '$': 5, \"''\": 6, '(': 7, ')': 8, ',': 9, '.': 10, ':': 11, 'CC': 12, 'CD': 13, 'DT': 14, 'EX': 15, 'FW': 16, 'IN': 17, 'JJ': 18, 'JJR': 19, 'JJS': 20, 'LS': 21, 'MD': 22, 'NN': 23, 'NNP': 24, 'NNPS': 25, 'NNS': 26, 'PDT': 27, 'POS': 28, 'PRP': 29, 'PRP$': 30, 'RB': 31, 'RBR': 32, 'RBS': 33, 'RP': 34, 'SYM': 35, 'TO': 36, 'UH': 37, 'VB': 38, 'VBD': 39, 'VBG': 40, 'VBN': 41, 'VBP': 42, 'VBZ': 43, 'WDT': 44, 'WP': 45, 'WP$': 46, 'WRB': 47, '``': 48}\n",
      "idx_pos_mappings - [0, 1, 2, 3, '#', '$', \"''\", '(', ')', ',', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n",
      "pos_idx_mappings - {'<pad>': 0, '<unk>': 1, '<root>': 2, '<root_pos>': 3, '#': 4, '$': 5, \"''\": 6, '(': 7, ')': 8, ',': 9, '.': 10, ':': 11, 'CC': 12, 'CD': 13, 'DT': 14, 'EX': 15, 'FW': 16, 'IN': 17, 'JJ': 18, 'JJR': 19, 'JJS': 20, 'LS': 21, 'MD': 22, 'NN': 23, 'NNP': 24, 'NNPS': 25, 'NNS': 26, 'PDT': 27, 'POS': 28, 'PRP': 29, 'PRP$': 30, 'RB': 31, 'RBR': 32, 'RBS': 33, 'RP': 34, 'SYM': 35, 'TO': 36, 'UH': 37, 'VB': 38, 'VBD': 39, 'VBG': 40, 'VBN': 41, 'VBP': 42, 'VBZ': 43, 'WDT': 44, 'WP': 45, 'WP$': 46, 'WRB': 47, '``': 48}\n"
     ]
    }
   ],
   "source": [
    "from data_handling import DepDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "print(\"path_train -\", path_train)\n",
    "print(\"path_test -\", path_test)\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "train = DepDataset(word_dict_all, pos_dict_all, data_dir, 'train.labeled', padding=False)\n",
    "train_dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test = DepDataset(word_dict_all, pos_dict_all, data_dir, 'test.labeled', padding=False, train_word_dict=word_dict_train)\n",
    "test_dataloader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# train = DepDataset(word_dict, pos_dict, data_dir, 'train_short', padding=False)\n",
    "# train_dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# test = DepDataset(word_dict, pos_dict, data_dir, 'test_short', padding=False)\n",
    "# test_dataloader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Sentences  5000\n",
      "Number of Test Sentences  1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Train Sentences \", len(train))\n",
    "print(\"Number of Test Sentences \",len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "unknown accuracy: 89.80870025150469\n",
      "Epoch: 1 | Training Loss: 1.2316 | Training accuracy: 62.865% | Test Loss: 0.4446 | Test accuracy: 86.891% | Epoch Time: 42.57 secs\n",
      "saving model\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "unknown accuracy: 91.59222696123065\n",
      "Epoch: 2 | Training Loss: 0.3566 | Training accuracy: 89.407% | Test Loss: 0.3674 | Test accuracy: 88.918% | Epoch Time: 38.04 secs\n",
      "saving model\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "unknown accuracy: 91.94726655058759\n",
      "Epoch: 3 | Training Loss: 0.2354 | Training accuracy: 92.760% | Test Loss: 0.3706 | Test accuracy: 89.217% | Epoch Time: 37.88 secs\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "unknown accuracy: 90.98199975506249\n",
      "Epoch: 4 | Training Loss: 0.1782 | Training accuracy: 94.522% | Test Loss: 0.3879 | Test accuracy: 89.116% | Epoch Time: 37.88 secs\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "unknown accuracy: 92.20225005280356\n",
      "Epoch: 5 | Training Loss: 0.1382 | Training accuracy: 95.767% | Test Loss: 0.3944 | Test accuracy: 89.637% | Epoch Time: 37.70 secs\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "unknown accuracy: 91.68501479387088\n",
      "Epoch: 6 | Training Loss: 0.1003 | Training accuracy: 96.926% | Test Loss: 0.4191 | Test accuracy: 89.204% | Epoch Time: 37.73 secs\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "unknown accuracy: 91.66012612507078\n",
      "Epoch: 7 | Training Loss: 0.0796 | Training accuracy: 97.552% | Test Loss: 0.4610 | Test accuracy: 89.315% | Epoch Time: 37.64 secs\n",
      "early stopping reached, stop training\n",
      "==> Finished Training ...\n"
     ]
    }
   ],
   "source": [
    "#### TRAIN BASIC MODEL\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from model import DnnSepParser\n",
    "from trainer import Trainer\n",
    "from loss import NllLoss, HingeLoss\n",
    "from utils import IGNORE_IDX\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "WORD_EMBEDDING_DIM = 100\n",
    "TAG_EMBEDDING_DIM = 25\n",
    "HIDDEN_FC_DIM = 100\n",
    "STACK_LSTM_NUM = 2\n",
    "word_vocab_size = len(train.word_idx_mappings)\n",
    "tag_vocab_size = len(train.pos_idx_mappings)\n",
    "max_sentence_len = max(train.max_seq_len, test.max_seq_len)\n",
    "ACCUMULATE_GRAD_STEPS = 50\n",
    "NUM_EPOCHS = 30\n",
    "len_train = len(train)\n",
    "len_test = len(test)\n",
    "\n",
    "\n",
    "\n",
    "model = DnnSepParser(WORD_EMBEDDING_DIM, TAG_EMBEDDING_DIM, STACK_LSTM_NUM, word_vocab_size, tag_vocab_size, hidden_fc_dim=100)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "loss_function = NllLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "trainer = Trainer(model, optimizer, loss_function, device)\n",
    "\n",
    "trainer.train_dep_parser(NUM_EPOCHS, train_dataloader, test_dataloader, ACCUMULATE_GRAD_STEPS, len_train, len_test, early_stopping=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "unknown accuracy: 89.90104435676392\n",
      "Epoch: 1 | Training Loss: 1.2086 | Training accuracy: 64.291% | Test Loss: 0.4402 | Test accuracy: 86.687% | Epoch Time: 56.76 secs\n",
      "saving model\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "unknown accuracy: 91.48669971548202\n",
      "Epoch: 2 | Training Loss: 0.3432 | Training accuracy: 89.806% | Test Loss: 0.3638 | Test accuracy: 88.960% | Epoch Time: 51.91 secs\n",
      "saving model\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "unknown accuracy: 92.9754050787261\n",
      "Epoch: 3 | Training Loss: 0.1830 | Training accuracy: 94.614% | Test Loss: 0.3242 | Test accuracy: 90.527% | Epoch Time: 51.65 secs\n",
      "saving model\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "unknown accuracy: 92.80051880605387\n",
      "Epoch: 4 | Training Loss: 0.1205 | Training accuracy: 96.436% | Test Loss: 0.3305 | Test accuracy: 90.711% | Epoch Time: 51.69 secs\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "unknown accuracy: 92.67063536436231\n",
      "Epoch: 5 | Training Loss: 0.0875 | Training accuracy: 97.646% | Test Loss: 0.3340 | Test accuracy: 90.623% | Epoch Time: 51.49 secs\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "unknown accuracy: 92.8867660970982\n",
      "Epoch: 6 | Training Loss: 0.0830 | Training accuracy: 97.765% | Test Loss: 0.3376 | Test accuracy: 90.666% | Epoch Time: 51.43 secs\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "unknown accuracy: 92.82819408280663\n",
      "Epoch: 7 | Training Loss: 0.0797 | Training accuracy: 97.860% | Test Loss: 0.3378 | Test accuracy: 90.669% | Epoch Time: 51.45 secs\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "unknown accuracy: 92.82819408280663\n",
      "Epoch: 8 | Training Loss: 0.0790 | Training accuracy: 97.909% | Test Loss: 0.3381 | Test accuracy: 90.669% | Epoch Time: 51.33 secs\n",
      "early stopping reached, stop training\n",
      "==> Finished Training ...\n"
     ]
    }
   ],
   "source": [
    "#### TRAIN ADVANCED MODEL\n",
    "\n",
    "WORD_EMBEDDING_DIM = 250\n",
    "TAG_EMBEDDING_DIM = 25\n",
    "HIDDEN_FC_DIM = 500\n",
    "STACK_LSTM_NUM = 2\n",
    "ACCUMULATE_GRAD_STEPS = 50\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "model = DnnSepParser(WORD_EMBEDDING_DIM, TAG_EMBEDDING_DIM, STACK_LSTM_NUM, word_vocab_size, tag_vocab_size, hidden_fc_dim=HIDDEN_FC_DIM, is_advanced=True)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "loss_function = NllLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "trainer = Trainer(model, optimizer, loss_function, device, scheduler)\n",
    "\n",
    "trainer.train_dep_parser(NUM_EPOCHS, train_dataloader, test_dataloader, ACCUMULATE_GRAD_STEPS, len_train, len_test, early_stopping=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
