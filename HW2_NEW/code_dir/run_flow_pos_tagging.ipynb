{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import get_vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data_dir = 'data_old'\n",
    "# path_train = os.path.join(data_dir, 'train1_short.wtag')\n",
    "# path_test = os.path.join(data_dir, 'test1_short.wtag')\n",
    "path_train = os.path.join(data_dir, 'train.wtag')\n",
    "path_test = os.path.join(data_dir, 'test.wtag')\n",
    "paths_list = [path_train, path_test]\n",
    "word_dict, pos_dict = get_vocabs(paths_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_train - data_old/train.wtag\n",
      "path_test - data_old/test.wtag\n",
      "idx_pos_mappings - [0, 1, '#', '$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n",
      "pos_idx_mappings - {'<pad>': 0, '<unk>': 1, '#': 2, '$': 3, \"''\": 4, ',': 5, '-LRB-': 6, '-RRB-': 7, '.': 8, ':': 9, 'CC': 10, 'CD': 11, 'DT': 12, 'EX': 13, 'FW': 14, 'IN': 15, 'JJ': 16, 'JJR': 17, 'JJS': 18, 'MD': 19, 'NN': 20, 'NNP': 21, 'NNPS': 22, 'NNS': 23, 'PDT': 24, 'POS': 25, 'PRP': 26, 'PRP$': 27, 'RB': 28, 'RBR': 29, 'RBS': 30, 'RP': 31, 'SYM': 32, 'TO': 33, 'UH': 34, 'VB': 35, 'VBD': 36, 'VBG': 37, 'VBN': 38, 'VBP': 39, 'VBZ': 40, 'WDT': 41, 'WP': 42, 'WP$': 43, 'WRB': 44, '``': 45}\n",
      "idx_pos_mappings - [0, 1, '#', '$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n",
      "pos_idx_mappings - {'<pad>': 0, '<unk>': 1, '#': 2, '$': 3, \"''\": 4, ',': 5, '-LRB-': 6, '-RRB-': 7, '.': 8, ':': 9, 'CC': 10, 'CD': 11, 'DT': 12, 'EX': 13, 'FW': 14, 'IN': 15, 'JJ': 16, 'JJR': 17, 'JJS': 18, 'MD': 19, 'NN': 20, 'NNP': 21, 'NNPS': 22, 'NNS': 23, 'PDT': 24, 'POS': 25, 'PRP': 26, 'PRP$': 27, 'RB': 28, 'RBR': 29, 'RBS': 30, 'RP': 31, 'SYM': 32, 'TO': 33, 'UH': 34, 'VB': 35, 'VBD': 36, 'VBG': 37, 'VBN': 38, 'VBP': 39, 'VBZ': 40, 'WDT': 41, 'WP': 42, 'WP$': 43, 'WRB': 44, '``': 45}\n"
     ]
    }
   ],
   "source": [
    "from data_handling import PosDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "print(\"path_train -\", path_train)\n",
    "print(\"path_test -\", path_test)\n",
    "BATCH_SIZE = 1\n",
    "paths_list = [path_train, path_test]\n",
    "word_dict, pos_dict = get_vocabs(paths_list)\n",
    "train = PosDataset(word_dict, pos_dict, data_dir, 'train', padding=False)\n",
    "train_dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test = PosDataset(word_dict, pos_dict, data_dir, 'test', padding=False)\n",
    "test_dataloader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Tagged Sentences  5000\n",
      "Number of Test Tagged Sentences  1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Train Tagged Sentences \", len(train))\n",
    "print(\"Number of Test Tagged Sentences \",len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word embeddings shape: torch.Size([15212, 300])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from model import DnnPosTagger\n",
    "from trainer import Trainer\n",
    "\n",
    "WORD_EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 100\n",
    "NUM_LAYERS = 2\n",
    "word_vocab_size = len(train.word_idx_mappings)\n",
    "tag_vocab_size = len(train.pos_idx_mappings)\n",
    "\n",
    "model = DnnPosTagger(train_dataloader.dataset.word_vectors, HIDDEN_DIM, NUM_LAYERS, word_vocab_size, tag_vocab_size)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "acumulate_grad_steps = 50 # This is the actual batch_size, while we officially use batch_size=1\n",
    "trainer = Trainer(model, optimizer, loss_function, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/hw2/code_dir/trainer.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  acc += torch.mean(torch.tensor(pos_idx_tensor.to(\"cpu\") == indices.to(\"cpu\"), dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 0.0148 | Training accuracy: 97.040% | Test accuracy: 94.363% | Epoch Time: 36.04 secs\n",
      "saving model\n",
      "Epoch: 2 | Loss: 0.0020 | Training accuracy: 98.328% | Test accuracy: 94.877% | Epoch Time: 36.10 secs\n",
      "saving model\n",
      "Epoch: 3 | Loss: 0.0012 | Training accuracy: 98.843% | Test accuracy: 94.831% | Epoch Time: 36.00 secs\n",
      "Epoch: 4 | Loss: 0.0008 | Training accuracy: 99.290% | Test accuracy: 94.779% | Epoch Time: 36.05 secs\n",
      "Epoch: 5 | Loss: 0.0005 | Training accuracy: 99.444% | Test accuracy: 94.820% | Epoch Time: 36.09 secs\n",
      "Epoch: 6 | Loss: 0.0004 | Training accuracy: 99.658% | Test accuracy: 94.829% | Epoch Time: 35.78 secs\n",
      "Epoch: 7 | Loss: 0.0003 | Training accuracy: 99.764% | Test accuracy: 94.780% | Epoch Time: 35.80 secs\n",
      "Epoch: 8 | Loss: 0.0002 | Training accuracy: 99.826% | Test accuracy: 94.703% | Epoch Time: 35.85 secs\n",
      "Epoch: 9 | Loss: 0.0002 | Training accuracy: 99.863% | Test accuracy: 94.659% | Epoch Time: 35.87 secs\n",
      "Epoch: 10 | Loss: 0.0001 | Training accuracy: 99.870% | Test accuracy: 94.927% | Epoch Time: 36.05 secs\n",
      "saving model\n",
      "Epoch: 11 | Loss: 0.0001 | Training accuracy: 99.905% | Test accuracy: 94.772% | Epoch Time: 35.99 secs\n",
      "Epoch: 12 | Loss: 0.0001 | Training accuracy: 99.861% | Test accuracy: 94.668% | Epoch Time: 35.94 secs\n",
      "Epoch: 13 | Loss: 0.0002 | Training accuracy: 99.623% | Test accuracy: 94.162% | Epoch Time: 36.23 secs\n",
      "Epoch: 14 | Loss: 0.0005 | Training accuracy: 99.140% | Test accuracy: 93.723% | Epoch Time: 35.96 secs\n",
      "Epoch: 15 | Loss: 0.0008 | Training accuracy: 99.136% | Test accuracy: 93.622% | Epoch Time: 35.98 secs\n",
      "==> Finished Training ...\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "acumulate_grad_steps = 50\n",
    "len_train = len(train)\n",
    "len_test = len(test)\n",
    "trainer.train(EPOCHS, train_dataloader, test_dataloader, acumulate_grad_steps, len_train, len_test, early_stopping=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-nlp_hw2]",
   "language": "python",
   "name": "conda-env-.conda-nlp_hw2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
