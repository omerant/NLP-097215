{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from utils import get_vocabs_dep_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data_new'\n",
    "path_train = os.path.join(data_dir, 'train.labeled')\n",
    "path_test = os.path.join(data_dir, 'test.labeled')\n",
    "# path_train = os.path.join(data_dir, 'train_short.labeled')\n",
    "# path_test = os.path.join(data_dir, 'test_short.labeled')\n",
    "\n",
    "# get only train vocabs to know which words are unknown in test\n",
    "paths_list_train = [path_train]\n",
    "word_dict_train, pos_dict_train = get_vocabs_dep_parser(paths_list_train)\n",
    "\n",
    "paths_list_all = [path_train, path_test]\n",
    "word_dict_all, pos_dict_all = get_vocabs_dep_parser(paths_list_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_train - data_new\\train.labeled\n",
      "path_test - data_new\\test.labeled\n",
      "idx_pos_mappings - [0, 1, 2, '#', '$', \"''\", '(', ')', ',', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n",
      "pos_idx_mappings - {'<pad>': 0, '<unk>': 1, '<root>': 2, '#': 3, '$': 4, \"''\": 5, '(': 6, ')': 7, ',': 8, '.': 9, ':': 10, 'CC': 11, 'CD': 12, 'DT': 13, 'EX': 14, 'FW': 15, 'IN': 16, 'JJ': 17, 'JJR': 18, 'JJS': 19, 'LS': 20, 'MD': 21, 'NN': 22, 'NNP': 23, 'NNPS': 24, 'NNS': 25, 'PDT': 26, 'POS': 27, 'PRP': 28, 'PRP$': 29, 'RB': 30, 'RBR': 31, 'RBS': 32, 'RP': 33, 'SYM': 34, 'TO': 35, 'UH': 36, 'VB': 37, 'VBD': 38, 'VBG': 39, 'VBN': 40, 'VBP': 41, 'VBZ': 42, 'WDT': 43, 'WP': 44, 'WP$': 45, 'WRB': 46, '``': 47}\n",
      "idx_pos_mappings - [0, 1, 2, '#', '$', \"''\", '(', ')', ',', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n",
      "pos_idx_mappings - {'<pad>': 0, '<unk>': 1, '<root>': 2, '#': 3, '$': 4, \"''\": 5, '(': 6, ')': 7, ',': 8, '.': 9, ':': 10, 'CC': 11, 'CD': 12, 'DT': 13, 'EX': 14, 'FW': 15, 'IN': 16, 'JJ': 17, 'JJR': 18, 'JJS': 19, 'LS': 20, 'MD': 21, 'NN': 22, 'NNP': 23, 'NNPS': 24, 'NNS': 25, 'PDT': 26, 'POS': 27, 'PRP': 28, 'PRP$': 29, 'RB': 30, 'RBR': 31, 'RBS': 32, 'RP': 33, 'SYM': 34, 'TO': 35, 'UH': 36, 'VB': 37, 'VBD': 38, 'VBG': 39, 'VBN': 40, 'VBP': 41, 'VBZ': 42, 'WDT': 43, 'WP': 44, 'WP$': 45, 'WRB': 46, '``': 47}\n"
     ]
    }
   ],
   "source": [
    "from data_handling import DepDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "print(\"path_train -\", path_train)\n",
    "print(\"path_test -\", path_test)\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "train = DepDataset(word_dict_all, pos_dict_all, data_dir, 'train', padding=False)\n",
    "train_dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test = DepDataset(word_dict_all, pos_dict_all, data_dir, 'test', padding=False, train_word_dict=word_dict_train)\n",
    "test_dataloader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# train = DepDataset(word_dict, pos_dict, data_dir, 'train_short', padding=False)\n",
    "# train_dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# test = DepDataset(word_dict, pos_dict, data_dir, 'test_short', padding=False)\n",
    "# test_dataloader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Sentences  5000\n",
      "Number of Test Sentences  1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Train Sentences \", len(train))\n",
    "print(\"Number of Test Sentences \",len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.6818, -7.4735, -7.5403, -5.9936, -1.9239, -6.1666, -5.2465, -1.9967,\n",
      "         -5.7537, -6.3410, -2.6516, -6.0935, -1.8355, -6.4731, -2.2647, -6.2521,\n",
      "         -2.9862, -4.6957, -7.6173, -5.5102, -2.3712, -5.7957, -2.1291, -4.5326,\n",
      "         -6.1532, -5.7552, -2.7543],\n",
      "        [-5.2558, -6.8507, -6.9314, -5.4912, -1.9917, -5.6839, -4.8899, -2.0653,\n",
      "         -5.3224, -5.7999, -2.5966, -5.5804, -1.8625, -5.9163, -2.3013, -5.7352,\n",
      "         -3.0142, -4.4456, -7.0152, -5.1079, -2.3579, -5.3491, -2.2078, -4.3348,\n",
      "         -5.6650, -5.3040, -2.6838],\n",
      "        [-5.9484, -7.4718, -7.5311, -6.0968, -1.7503, -6.4754, -5.4487, -1.8939,\n",
      "         -6.0902, -6.4771, -2.9172, -6.2186, -1.7504, -6.5557, -2.3128, -6.4044,\n",
      "         -3.2906, -5.1238, -7.6109, -5.7305, -2.5263, -5.9196, -1.9863, -4.9368,\n",
      "         -6.4009, -5.9646, -2.9926],\n",
      "        [-3.8619, -4.8232, -4.9425, -4.3884, -2.4595, -3.9651, -4.0768, -2.4759,\n",
      "         -3.8648, -4.3826, -2.6221, -4.3773, -2.3251, -4.4842, -2.5440, -4.2554,\n",
      "         -2.8346, -3.4011, -4.9393, -4.0586, -2.5452, -4.2685, -2.5401, -3.3901,\n",
      "         -4.0927, -4.1141, -2.6473],\n",
      "        [-6.8326, -7.7875, -7.7886, -7.2184, -1.3601, -7.0547, -6.7540, -1.6251,\n",
      "         -6.8796, -7.3557, -3.9368, -7.2659, -2.2130, -7.4382, -2.5853, -7.2730,\n",
      "         -3.8247, -6.0740, -7.8097, -6.8927, -3.3223, -7.0786, -1.3941, -5.8777,\n",
      "         -7.1361, -7.0431, -3.9686],\n",
      "        [-5.7497, -7.5220, -7.5971, -6.0556, -1.9081, -6.2514, -5.3011, -1.9827,\n",
      "         -5.8378, -6.4154, -2.6749, -6.1609, -1.8240, -6.5340, -2.2588, -6.3133,\n",
      "         -3.0021, -4.7763, -7.6717, -5.5781, -2.3787, -5.8494, -2.1175, -4.6055,\n",
      "         -6.2310, -5.8280, -2.7707],\n",
      "        [-3.5281, -4.5365, -4.6417, -4.1813, -2.6584, -3.5964, -3.8100, -2.6644,\n",
      "         -3.5160, -4.0561, -2.7276, -4.0945, -2.5408, -4.2342, -2.7005, -3.9318,\n",
      "         -2.8696, -3.1730, -4.6018, -3.7485, -2.6875, -4.0572, -2.7114, -3.1655,\n",
      "         -3.7118, -3.7919, -2.7577],\n",
      "        [-6.2122, -7.8356, -7.8875, -6.9338, -1.6059, -6.6897, -6.1651, -1.7353,\n",
      "         -6.4150, -7.1196, -3.3374, -6.9891, -2.0858, -7.2385, -2.3019, -6.8891,\n",
      "         -3.1372, -5.2825, -7.9062, -6.3243, -2.8365, -6.6349, -1.6292, -4.9936,\n",
      "         -6.7407, -6.5605, -3.3555],\n",
      "        [-4.6738, -6.4028, -6.5400, -5.1775, -2.1629, -5.0644, -4.5483, -2.2097,\n",
      "         -4.7353, -5.3939, -2.5224, -5.2196, -1.9956, -5.5128, -2.3539, -5.2361,\n",
      "         -2.7935, -3.8833, -6.5908, -4.6913, -2.3657, -4.9735, -2.3336, -3.7884,\n",
      "         -5.0988, -4.8696, -2.5968],\n",
      "        [-3.5678, -4.3882, -4.4485, -4.1079, -2.6850, -3.5217, -3.8212, -2.7002,\n",
      "         -3.4661, -3.9688, -2.7135, -4.0253, -2.5371, -4.1631, -2.7340, -3.9221,\n",
      "         -2.9120, -3.1988, -4.4126, -3.7620, -2.6875, -4.0578, -2.7687, -3.2187,\n",
      "         -3.6640, -3.7813, -2.7554],\n",
      "        [-6.4585, -8.0689, -8.1403, -6.9130, -1.6815, -6.9806, -6.1596, -1.8040,\n",
      "         -6.6303, -7.2427, -3.0748, -7.0265, -1.8690, -7.3122, -2.2686, -7.0664,\n",
      "         -3.1697, -5.4333, -8.1824, -6.4182, -2.6232, -6.6423, -1.8232, -5.1724,\n",
      "         -6.9935, -6.6750, -3.1429],\n",
      "        [-3.4623, -4.2680, -4.3338, -4.0447, -2.7508, -3.4393, -3.7359, -2.7587,\n",
      "         -3.3932, -3.8673, -2.7918, -3.9384, -2.6259, -4.0723, -2.7875, -3.8007,\n",
      "         -2.9367, -3.1630, -4.2816, -3.6588, -2.7636, -3.9714, -2.8053, -3.1757,\n",
      "         -3.5604, -3.6776, -2.8241],\n",
      "        [-6.7737, -7.8060, -7.8245, -7.2207, -1.3789, -7.0130, -6.7210, -1.6329,\n",
      "         -6.8331, -7.3436, -3.8698, -7.2615, -2.1697, -7.4451, -2.5593, -7.2515,\n",
      "         -3.7734, -6.0042, -7.8354, -6.8593, -3.2688, -7.0705, -1.4216, -5.8092,\n",
      "         -7.1033, -7.0097, -3.9116],\n",
      "        [-3.5434, -4.4847, -4.5690, -4.1360, -2.6697, -3.5580, -3.7880, -2.6837,\n",
      "         -3.4815, -3.9825, -2.7334, -4.0360, -2.5218, -4.1958, -2.7244, -3.9141,\n",
      "         -2.9018, -3.1932, -4.5216, -3.7289, -2.6943, -4.0538, -2.7477, -3.2006,\n",
      "         -3.6729, -3.7585, -2.7741],\n",
      "        [-6.4133, -7.9585, -7.9989, -7.0570, -1.5765, -6.8448, -6.3238, -1.7197,\n",
      "         -6.5712, -7.2552, -3.3800, -7.1204, -2.0369, -7.3753, -2.3206, -7.0673,\n",
      "         -3.2263, -5.4602, -8.0222, -6.5005, -2.8580, -6.7955, -1.6296, -5.1845,\n",
      "         -6.9075, -6.7293, -3.4130],\n",
      "        [-3.7728, -5.0255, -5.1354, -4.3583, -2.5084, -3.8939, -3.9222, -2.5349,\n",
      "         -3.7380, -4.3030, -2.6172, -4.2917, -2.3267, -4.5055, -2.5997, -4.2154,\n",
      "         -2.8380, -3.2901, -5.1204, -3.9148, -2.5586, -4.2488, -2.6304, -3.2748,\n",
      "         -3.9889, -3.9829, -2.6770],\n",
      "        [-5.0896, -7.1566, -7.2928, -5.9044, -1.9750, -5.7196, -5.0394, -2.0217,\n",
      "         -5.3484, -6.1538, -2.7344, -5.9607, -2.0738, -6.2499, -2.2551, -5.8287,\n",
      "         -2.6928, -4.1684, -7.3248, -5.1963, -2.4677, -5.5214, -2.0372, -3.9305,\n",
      "         -5.7187, -5.4550, -2.7625],\n",
      "        [-4.3295, -6.0994, -6.2358, -4.9305, -2.2594, -4.7022, -4.2776, -2.2960,\n",
      "         -4.3936, -5.0726, -2.5347, -4.9302, -2.1049, -5.2278, -2.4107, -4.9023,\n",
      "         -2.7448, -3.6079, -6.2685, -4.3781, -2.4126, -4.7136, -2.4005, -3.5137,\n",
      "         -4.7371, -4.5456, -2.6087],\n",
      "        [-4.5707, -6.0213, -6.1231, -4.9196, -2.2005, -4.8340, -4.4160, -2.2493,\n",
      "         -4.5553, -5.0856, -2.4993, -4.9498, -2.0011, -5.2374, -2.3870, -5.0300,\n",
      "         -2.8833, -3.8721, -6.1799, -4.5420, -2.3604, -4.8150, -2.4014, -3.8298,\n",
      "         -4.8824, -4.6751, -2.5846],\n",
      "        [-3.5890, -4.5179, -4.6064, -4.1756, -2.6468, -3.6019, -3.8548, -2.6584,\n",
      "         -3.5267, -4.0679, -2.6928, -4.1041, -2.5211, -4.2360, -2.6938, -3.9758,\n",
      "         -2.8663, -3.1948, -4.5743, -3.8013, -2.6610, -4.0864, -2.7163, -3.2003,\n",
      "         -3.7370, -3.8362, -2.7287],\n",
      "        [-6.5708, -8.1068, -8.1627, -7.0826, -1.6122, -7.0392, -6.3528, -1.7506,\n",
      "         -6.7273, -7.3598, -3.2478, -7.1783, -1.9309, -7.4446, -2.2956, -7.1888,\n",
      "         -3.2336, -5.5638, -8.1958, -6.5827, -2.7471, -6.8233, -1.7199, -5.2962,\n",
      "         -7.0805, -6.8249, -3.3025],\n",
      "        [-3.3880, -4.1417, -4.2048, -3.9666, -2.8196, -3.3769, -3.6553, -2.8261,\n",
      "         -3.3387, -3.7601, -2.8560, -3.8429, -2.7185, -3.9714, -2.8508, -3.6907,\n",
      "         -2.9697, -3.1441, -4.1393, -3.5724, -2.8326, -3.8843, -2.8629, -3.1532,\n",
      "         -3.4755, -3.5856, -2.8831],\n",
      "        [-6.4275, -7.7520, -7.7636, -7.0635, -1.4711, -6.7598, -6.4239, -1.6597,\n",
      "         -6.5498, -7.1777, -3.6843, -7.0938, -2.1945, -7.3112, -2.4330, -7.0143,\n",
      "         -3.4432, -5.6016, -7.7779, -6.5471, -3.1121, -6.8456, -1.4687, -5.3465,\n",
      "         -6.8351, -6.7380, -3.6971],\n",
      "        [-4.0920, -5.7901, -5.9384, -4.7635, -2.3341, -4.4433, -4.1496, -2.3612,\n",
      "         -4.1755, -4.8552, -2.5608, -4.7461, -2.2179, -5.0003, -2.4538, -4.6549,\n",
      "         -2.7220, -3.4458, -5.9556, -4.2074, -2.4612, -4.5354, -2.4418, -3.3584,\n",
      "         -4.4886, -4.3540, -2.6152],\n",
      "        [-4.3685, -5.9093, -6.0436, -4.8706, -2.2588, -4.6590, -4.3382, -2.2992,\n",
      "         -4.3914, -5.0127, -2.5153, -4.8900, -2.0763, -5.1432, -2.4120, -4.8799,\n",
      "         -2.7932, -3.6774, -6.0813, -4.4310, -2.3958, -4.7082, -2.4201, -3.6184,\n",
      "         -4.7203, -4.5671, -2.5837],\n",
      "        [-3.5602, -4.4684, -4.5456, -4.1423, -2.6696, -3.5556, -3.8226, -2.6841,\n",
      "         -3.4867, -4.0106, -2.7099, -4.0588, -2.5366, -4.2002, -2.7202, -3.9369,\n",
      "         -2.8902, -3.1840, -4.5086, -3.7636, -2.6816, -4.0659, -2.7457, -3.1937,\n",
      "         -3.6883, -3.7919, -2.7491],\n",
      "        [-6.9919, -8.2050, -8.1989, -7.2791, -1.4949, -7.3133, -6.6625, -1.6796,\n",
      "         -7.0350, -7.5162, -3.5021, -7.3562, -1.8855, -7.6368, -2.3914, -7.4755,\n",
      "         -3.5977, -6.0682, -8.2408, -6.9066, -2.9179, -7.1319, -1.6563, -5.8416,\n",
      "         -7.3524, -7.1103, -3.5871]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from model import DnnSepParser\n",
    "from trainer import Trainer\n",
    "from loss import NllLoss\n",
    "from utils import IGNORE_IDX\n",
    "\n",
    "WORD_EMBEDDING_DIM = 100\n",
    "TAG_EMBEDDING_DIM = 25\n",
    "NUM_LAYERS = [2, 3, 4, 5, 6]\n",
    "word_vocab_size = len(train.word_idx_mappings)\n",
    "tag_vocab_size = len(train.pos_idx_mappings)\n",
    "max_sentence_len = max(train.max_seq_len, test.max_seq_len)\n",
    "\n",
    "acumulate_grad_steps = 50\n",
    "len_train = len(train)\n",
    "len_test = len(test)\n",
    "\n",
    "for num_layer in NUM_LAYERS:\n",
    "    model = DnnSepParser(WORD_EMBEDDING_DIM, TAG_EMBEDDING_DIM, num_layer, word_vocab_size, tag_vocab_size, max_sentence_len)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    # TODO: use our function with ignore index\n",
    "    # loss_function = nn.NLLLoss(ignore_index=IGNORE_IDX)\n",
    "#     loss_function = nn.NLLLoss()\n",
    "    loss_function = NllLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    acumulate_grad_steps = 50 # This is the actual batch_size, while we officially use batch_size=1\n",
    "    trainer = Trainer(model, optimizer, loss_function, device)\n",
    "\n",
    "#     torch.manual_seed(1)\n",
    "    EPOCHS = 100\n",
    "\n",
    "    trainer.train_dep_parser(EPOCHS, train_dataloader, test_dataloader, acumulate_grad_steps, len_train, len_test, early_stopping=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}